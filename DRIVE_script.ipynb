{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLq00TKThUG4"
      },
      "outputs": [],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell once, then go to 'Runtime' -> 'Restart Runtime', then comment this cell out\n",
        "!pip install miscnn\n",
        "!pip install matplotlib==3.3.1"
      ],
      "metadata": {
        "id": "oMGAWEzYhXNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import argparse\n",
        "import math\n",
        "import json\n",
        "import skimage\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "\n",
        "# MIScnn\n",
        "from miscnn.neural_network.metrics import identify_axis\n",
        "from miscnn.processing.data_augmentation import Data_Augmentation\n",
        "from miscnn.processing.subfunctions.normalization import Normalization\n",
        "from miscnn.processing.subfunctions.resize import Resize\n",
        "from miscnn.processing.subfunctions.clipping import Clipping\n",
        "from miscnn.processing.subfunctions.resampling import Resampling\n",
        "from miscnn.processing.preprocessor import Preprocessor\n",
        "from miscnn.neural_network.model import Neural_Network\n",
        "from miscnn.neural_network.metrics import *\n",
        "import miscnn.neural_network.metrics\n",
        "\n",
        "from miscnn.neural_network.architecture.unet.standard import Architecture\n",
        "\n",
        "from miscnn.evaluation.cross_validation import run_fold, load_disk2fold\n",
        "from miscnn.data_loading.interfaces.image_io import Image_interface\n",
        "from miscnn.data_loading.data_io import Data_IO\n",
        "from miscnn.data_loading.data_io import backup_evaluation\n",
        "\n",
        "# Tensorflow\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "T0jaTYoShptt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating interface: single channel with 2 classes\n",
        "interface = Image_interface(pattern = \"img[0-9]*\" # Pattern may differ depending on folder structure\n",
        "                                 , img_type = 'rgb'\n",
        "                                 , img_format = 'png'\n",
        "                                 , classes = 2)\n",
        "\n",
        "# path to data folder\n",
        "data_path = \"/path/to/dataset\" # Path to DRIVE dataset\n",
        "\n",
        "# Generating dataloader\n",
        "data_io = Data_IO(interface, data_path, delete_batchDir=False)\n",
        "\n",
        "# Sample list\n",
        "sample_list = data_io.get_indiceslist()\n",
        "sample_list.sort()\n",
        "\n",
        "# Basic checks\n",
        "print(\"All samples: \" + str(len(sample_list)))\n",
        "sample = data_io.sample_loader(sample_list[0], load_seg=True)  \n",
        "print(\"Image dimension check:\",sample.img_data.shape, sample.seg_data.shape)"
      ],
      "metadata": {
        "id": "IueHGM6OiJ_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "data_aug = Data_Augmentation(cycles=6, scaling=False, rotations=True, elastic_deform=False, mirror=True,\n",
        "                             brightness=True, contrast=True, gamma=False, gaussian_noise=False)\n",
        "\n",
        "\n",
        "# Data preprocessing parameters\n",
        "sf_normalize = Normalization(mode='z-score')\n",
        "sf_resize = Resize((512,512))\n",
        "subfunctions = [sf_resize, sf_normalize]\n",
        "\n",
        "\n",
        "# Create preprocessing class\n",
        "pp = Preprocessor(data_io\n",
        "                  , data_aug=data_aug\n",
        "                  , batch_size=2\n",
        "                  , prepare_subfunctions=True\n",
        "                  , subfunctions=subfunctions\n",
        "                  , prepare_batches=False\n",
        "                  , analysis=\"fullimage\"\n",
        "                  , use_multiprocessing=False)"
      ],
      "metadata": {
        "id": "2nbwQg4wisn1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# U-Net\n",
        "architecture = Architecture()\n",
        "\n",
        "# Here the loss function is chosen:\n",
        "loss = asym_unified_focal_loss()\n",
        "\n",
        "# Create the Neural Network model\n",
        "model = Neural_Network(architecture=architecture\n",
        "                      , preprocessor=pp\n",
        "                      , loss=loss\n",
        "                      , metrics=[dice_soft]\n",
        "                      , batch_queue_size=3\n",
        "                      , workers=1\n",
        "                      , learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "6jSJXcS-iyA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "cb_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_delta=1e-7, cooldown=1, min_lr=1e-7)\n",
        "\n",
        "cb_es = EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=20, verbose=1, mode='min')"
      ],
      "metadata": {
        "id": "8UOvr0qljglu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run pipeline for cross-validation fold\n",
        "run_fold(fold=0\n",
        "         , model=model\n",
        "         , epochs=300\n",
        "         , evaluation_path='/path/to/folder'\n",
        "         , draw_figures=True\n",
        "         , callbacks=[cb_lr,cb_es]\n",
        "         , save_models=True\n",
        "        )"
      ],
      "metadata": {
        "id": "bWZQ_SWijoJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation code**"
      ],
      "metadata": {
        "id": "vAQ21iB_KqGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is used for evaluation\n",
        "\n",
        "path = os.path.join('/path/to/folder','fold_0','model.hdf5')\n",
        "training,validation = load_disk2fold(os.path.join('/path/to/folder','fold_0','testing.json'))\n",
        "evaluation_path = '/path/to/folder/fold_0'\n",
        "\n",
        "# load model\n",
        "model.load(path)\n",
        "\n",
        "\n",
        "def load_disk2fold(file_path):\n",
        "    with open(file_path, \"r\") as jsonfile:\n",
        "        sampling = json.load(jsonfile)\n",
        "        if \"TRAINING\" in sampling : training = sampling[\"TRAINING\"]\n",
        "        else : training = None\n",
        "        if \"VALIDATION\" in sampling : validation = sampling[\"VALIDATION\"]\n",
        "        else : validation = None\n",
        "    return training, validation\n",
        "\n",
        "\n",
        "# Calculate class-wise dice similarity coefficient\n",
        "def compute_dice(truth, pred, classes):\n",
        "    dice_scores = []\n",
        "    # Compute Dice for each class\n",
        "    i = 1\n",
        "    try:\n",
        "        pd = np.equal(pred, i)\n",
        "        gt = np.equal(truth[:,:,0], i)\n",
        "        dice = 2*np.logical_and(pd, gt).sum()/(pd.sum() + gt.sum())\n",
        "        dice_scores.append(dice)\n",
        "    except ZeroDivisionError:\n",
        "        dice_scores.append(0.0)\n",
        "    # Return computed Dice scores\n",
        "    return dice_scores\n",
        "\n",
        "\n",
        "def compute_rest(truth, pred, classes):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    # Compute precision, recall scores for each class\n",
        "    i = 1\n",
        "    try:\n",
        "        pd = np.equal(pred, i)\n",
        "        gt = np.equal(truth[:,:,0], i)\n",
        "        tp = np.logical_and(pd,gt).sum()\n",
        "        fp = np.logical_and(pd,np.logical_not(gt)).sum()\n",
        "        fn = np.logical_and(gt,np.logical_not(pd)).sum()\n",
        "        precision = tp/(tp+fp)\n",
        "        precision_scores.append(precision)\n",
        "    except ZeroDivisionError:\n",
        "        precision_scores.append(0.0) \n",
        "\n",
        "    try:\n",
        "        recall = tp/(tp+fn)\n",
        "        recall_scores.append(recall)\n",
        "    except ZeroDivisionError:\n",
        "        recall_scores.append(0.0)\n",
        "            \n",
        "    # Return computed precision, recall scores \n",
        "    return precision_scores, recall_scores\n",
        "\n",
        "# Initialize detailed validation scoring file\n",
        "classes_1 = [\"dice_score\"]\n",
        "classes_2 = [\"precision_score\"]  \n",
        "classes_3 = [\"recall_score\"]          \n",
        "header = [\"sample_id\"]\n",
        "header.extend(classes_1)\n",
        "header.extend(classes_2)\n",
        "header.extend(classes_3)\n",
        "backup_evaluation(header, evaluation_path, start=True)\n",
        "\n",
        "for sample_index in validation:\n",
        "        pred = model.predict([sample_index],return_output=True,activation_output=True)\n",
        "\n",
        "        # get prediction from list of predictions\n",
        "        pred = pred[0]\n",
        "\n",
        "        # Load the sample\n",
        "        sample = model.preprocessor.data_io.sample_loader(sample_index,\n",
        "                                                          load_seg=True,\n",
        "                                                          load_pred=False)\n",
        "        # Access image and ground truth segmentation data\n",
        "        img, seg = sample.img_data, sample.seg_data\n",
        "\n",
        "        # resize segmentation to size of prediction activations\n",
        "        seg_act = resize(seg,(pred.shape[0], pred.shape[1]),order=0, preserve_range=True,anti_aliasing=False)\n",
        "\n",
        "        # convert softmax predictions to classes\n",
        "        pred = np.argmax(pred,axis=-1)\n",
        "        \n",
        "        # resize final prediction to original image shape\n",
        "        pred = resize(pred,(seg.shape[0], seg.shape[1]),order=0, preserve_range=True,anti_aliasing=False)\n",
        "\n",
        "        # Compute segmentation metrics\n",
        "        dice_scores = compute_dice(seg, pred, 1)\n",
        "        precision_scores, recall_scores = compute_rest(seg, pred, 1)\n",
        "        \n",
        "        # Save detailed validation scores to file\n",
        "        scores = [sample_index]\n",
        "        scores.extend(dice_scores)\n",
        "        scores.extend(precision_scores)\n",
        "        scores.extend(recall_scores)\n",
        "        backup_evaluation(scores, evaluation_path, start=False)   "
      ],
      "metadata": {
        "id": "m2pbD58okRUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get final scores \n",
        "results_csv = pd.read_csv('/path/to/folder/fold_0/results.tsv', sep='\\t')\n",
        "print('Dice score in holdout test set: ', results_csv['dice_score'].mean())"
      ],
      "metadata": {
        "id": "dUONEWzDNK3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}